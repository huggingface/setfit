{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76571396-8f54-40ed-9e81-6c7531e6eaee",
   "metadata": {
    "id": "76571396-8f54-40ed-9e81-6c7531e6eaee"
   },
   "source": [
    "# Efficiently run SetFit Models with Optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead5bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this notebook using `numactl`` to gain better control on which resources you are running. \n",
    "# It is best to run on a single socket.\n",
    "\n",
    "# NUM_THREADS=<NUM_AVAILABLE_CORES>\n",
    "# OMP_NUM_THREADS=$NUM_THREADS numactl -C 0-\"$(($NUM_THREADS-1))\" -m 0 jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1e4e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install matplotlib -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55756fec-fc22-4590-84d7-2f3df37b9256",
   "metadata": {
    "id": "55756fec-fc22-4590-84d7-2f3df37b9256"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "class PerformanceBenchmark:\n",
    "    def __init__(self, model, dataset, optim_type):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "        self.enable_autocast = 'optimum' in self.optim_type.lower()\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        with torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "            preds = self.model.predict(self.dataset[\"text\"])\n",
    "        labels = self.dataset[\"label\"]\n",
    "        accuracy = metric.compute(predictions=preds, references=labels)\n",
    "        print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def compute_size(self):\n",
    "        state_dict = self.model.model_body.state_dict()\n",
    "        tmp_path = Path(\"model.pt\")\n",
    "        torch.save(state_dict, tmp_path)\n",
    "        # Calculate size in megabytes\n",
    "        size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
    "        # Delete temporary file\n",
    "        tmp_path.unlink()\n",
    "        print(f\"Model size (MB) - {size_mb:.2f}\")\n",
    "        return {\"size_mb\": size_mb}\n",
    "\n",
    "    def compute_latency(self, query=\"that loves its characters and communicates something rather beautiful about human nature\"):\n",
    "        latencies = []\n",
    "        # Warmup\n",
    "        for _ in range(10):\n",
    "            with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                _ = self.model([query])\n",
    "        # Timed run\n",
    "        for _ in range(1000):\n",
    "            start_time = perf_counter()\n",
    "            with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                _ = self.model([query])\n",
    "            latency = perf_counter() - start_time\n",
    "            latencies.append(latency)\n",
    "        # Compute run statistics\n",
    "        time_avg_ms = 1000 * np.mean(latencies)\n",
    "        time_std_ms = 1000 * np.std(latencies)\n",
    "        print(rf\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "        return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "    def compute_throughput(self, batch_sizes=[64, 512, 8192]):\n",
    "        results = {}\n",
    "        num_iters = 5\n",
    "        replications = int((max(batch_sizes) * (num_iters + 1)) / len(self.dataset))\n",
    "        replicated_ds = (self.dataset[\"text\"] * replications)[:max(batch_sizes) * num_iters]\n",
    "\n",
    "        s = \"\"\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"Batch size: {batch_size}\")\n",
    "            \n",
    "            throughputs = []\n",
    "            dataloader = iter(DataLoader(replicated_ds, batch_size=batch_size))\n",
    "            # Warmup\n",
    "            for _ in range(2):\n",
    "                with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                    _ = self.model(next(dataloader))\n",
    "\n",
    "            dataloader = iter(DataLoader(replicated_ds, batch_size=batch_size))\n",
    "            # Timed run\n",
    "            num_loops = num_iters * (max(batch_sizes) / batch_size)\n",
    "            assert int(num_loops) == num_loops\n",
    "            \n",
    "            for _ in range(int(num_loops)):\n",
    "                start_time = perf_counter()\n",
    "                with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                    _ = self.model(next(dataloader))\n",
    "                latency =  perf_counter() - start_time\n",
    "                throughputs.append(batch_size / latency)\n",
    "                \n",
    "            # Compute run statistics\n",
    "            avg_throughput = np.mean(throughputs)\n",
    "            std_throughput = np.std(throughputs)\n",
    "            print(rf\"Average throughput (bs={batch_size}) (samples/second): {avg_throughput:.2f} +\\- {std_throughput:.2f}\\n\")\n",
    "            results[f\"throughput_avg_{batch_size}\"] = avg_throughput\n",
    "            results[f\"throughput_std_{batch_size}\"] = std_throughput\n",
    "        return results\n",
    "        \n",
    "    def run_benchmark(self):\n",
    "        metrics = {self.optim_type: {}}\n",
    "        metrics[self.optim_type].update(self.compute_size())\n",
    "        metrics[self.optim_type].update(self.compute_accuracy())\n",
    "        metrics[self.optim_type].update(self.compute_latency())\n",
    "        metrics[self.optim_type].update(self.compute_throughput())\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "PurksLh3qcBa",
   "metadata": {
    "id": "PurksLh3qcBa"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_metrics(perf_metrics):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        plt.errorbar(\n",
    "            df_opt[\"time_avg_ms\"],\n",
    "            df_opt[\"accuracy\"] * 100,\n",
    "            xerr=df_opt[\"time_std_ms\"],\n",
    "            fmt=\"o\",\n",
    "            alpha=0.5,\n",
    "            ms=df_opt[\"size_mb\"] / 15,\n",
    "            label=idx,\n",
    "            capsize=5,\n",
    "            capthick=1,\n",
    "        )\n",
    "\n",
    "    legend = plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.ylim(63, 95)\n",
    "    # Use the slowest model to define the x-axis range\n",
    "    xlim = max([metrics[\"time_avg_ms\"] for metrics in perf_metrics.values()]) * 1.3\n",
    "    plt.xlim(0, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency with batch_size=1 (ms)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "u-w99Y2qW4lU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-w99Y2qW4lU",
    "outputId": "57f0b8f7-6dad-4e90-c779-658a7de6e960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 127.32\n",
      "Accuracy on test set - 0.906\n",
      "Average latency (ms) - 35.35 +\\- 5.18\n",
      "Batch size: 64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m small_model \u001b[38;5;241m=\u001b[39m SetFitModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoshew/bge-small-en-v1.5_setfit-sst2-english\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m pb \u001b[38;5;241m=\u001b[39m PerformanceBenchmark(model\u001b[38;5;241m=\u001b[39msmall_model, dataset\u001b[38;5;241m=\u001b[39mtest_dataset, optim_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbge-small (PyTorch)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m perf_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mpb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_benchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plot_metrics(perf_metrics)\n",
      "Cell \u001b[0;32mIn[8], line 101\u001b[0m, in \u001b[0;36mPerformanceBenchmark.run_benchmark\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m metrics[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_type]\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_accuracy())\n\u001b[1;32m    100\u001b[0m metrics[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_type]\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_latency())\n\u001b[0;32m--> 101\u001b[0m metrics[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_type]\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_throughput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "Cell \u001b[0;32mIn[8], line 84\u001b[0m, in \u001b[0;36mPerformanceBenchmark.compute_throughput\u001b[0;34m(self, batch_sizes)\u001b[0m\n\u001b[1;32m     82\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mcpu\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_autocast):\n\u001b[0;32m---> 84\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m latency \u001b[38;5;241m=\u001b[39m  perf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     86\u001b[0m throughputs\u001b[38;5;241m.\u001b[39mappend(batch_size \u001b[38;5;241m/\u001b[39m latency)\n",
      "File \u001b[0;32m~/dkorat/setfit/src/setfit/modeling.py:606\u001b[0m, in \u001b[0;36mSetFitModel.__call__\u001b[0;34m(self, inputs, batch_size, as_numpy, use_labels, show_progress_bar)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    576\u001b[0m     inputs: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    580\u001b[0m     show_progress_bar: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    581\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[torch\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray, List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict the various classes.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;124;03m            is a single string, then the output is a single label as well.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mas_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_numpy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dkorat/setfit/src/setfit/modeling.py:560\u001b[0m, in \u001b[0;36mSetFitModel.predict\u001b[0;34m(self, inputs, batch_size, as_numpy, use_labels, show_progress_bar)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_singular:\n\u001b[1;32m    559\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [inputs]\n\u001b[0;32m--> 560\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_head\u001b[38;5;241m.\u001b[39mpredict(embeddings)\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# If labels are defined, we don't have multilabels & the output is not already strings, then we convert to string labels\u001b[39;00m\n",
      "File \u001b[0;32m~/dkorat/setfit/src/setfit/modeling.py:452\u001b[0m, in \u001b[0;36mSetFitModel.encode\u001b[0;34m(self, inputs, batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m, inputs: List[\u001b[38;5;28mstr\u001b[39m], batch_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, show_progress_bar: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    439\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[torch\u001b[38;5;241m.\u001b[39mTensor, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert input sentences to embeddings using the `SentenceTransformer` body.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m        torch Tensor if this model has a differentiable Torch head, or otherwise as a numpy array.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_differentiable_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:165\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m features \u001b[38;5;241m=\u001b[39m batch_to_device(features, device)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 165\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    168\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/sentence_transformers/models/Transformer.py:66\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     64\u001b[0m     trans_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 66\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     69\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m'\u001b[39m: output_tokens, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m: features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]})\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1013\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1006\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1007\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1008\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1011\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1012\u001b[0m )\n\u001b[0;32m-> 1013\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1026\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:607\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    596\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    597\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    598\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    604\u001b[0m         output_attentions,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 607\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:436\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    428\u001b[0m         hidden_states,\n\u001b[1;32m    429\u001b[0m         attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m         output_attentions,\n\u001b[1;32m    435\u001b[0m     )\n\u001b[0;32m--> 436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_outputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/storage/sdp/anaconda3/envs/setfit-pr/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:388\u001b[0m, in \u001b[0;36mBertSelfOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    386\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    387\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 388\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(\u001b[43mhidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "test_dataset = load_dataset(\"SetFit/sst2\")[\"validation\"]\n",
    "from setfit import SetFitModel\n",
    "small_model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "pb = PerformanceBenchmark(model=small_model, dataset=test_dataset, optim_type=\"bge-small (PyTorch)\")\n",
    "perf_metrics = pb.run_benchmark()\n",
    "plot_metrics(perf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AiPUhOCNWRny",
   "metadata": {
    "id": "AiPUhOCNWRny"
   },
   "source": [
    "## 4. Optimizing with [`optimum-intel`](https://github.com/huggingface/optimum-intel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ea1d8-b82a-4a88-b3eb-2fa87582e6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: intel-extension-for-pytorch in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: psutil in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from intel-extension-for-pytorch) (5.9.7)\n",
      "Requirement already satisfied: numpy in /home/sdp/.local/lib/python3.10/site-packages (from intel-extension-for-pytorch) (1.25.2)\n",
      "Requirement already satisfied: packaging in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from intel-extension-for-pytorch) (23.2)\n",
      "Requirement already satisfied: intel-openmp in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (2024.0.0)\n",
      "Requirement already satisfied: optimum[neural-compressor] in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (1.16.2)\n",
      "Requirement already satisfied: coloredlogs in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (15.0.1)\n",
      "Requirement already satisfied: sympy in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (1.12)\n",
      "Requirement already satisfied: transformers>=4.26.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (4.36.2)\n",
      "Requirement already satisfied: torch>=1.11 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (2.1.0+cpu)\n",
      "Requirement already satisfied: packaging in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (23.2)\n",
      "Requirement already satisfied: numpy in /home/sdp/.local/lib/python3.10/site-packages (from optimum[neural-compressor]) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (0.20.2)\n",
      "Requirement already satisfied: datasets in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum[neural-compressor]) (2.16.1)\n",
      "Requirement already satisfied: optimum-intel>=1.12.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.12.4)\n",
      "Requirement already satisfied: filelock in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2023.10.0)\n",
      "Requirement already satisfied: requests in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]) (4.9.0)\n",
      "Requirement already satisfied: sentencepiece in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel>=1.12.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.1.99)\n",
      "Requirement already satisfied: scipy in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel>=1.12.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.11.4)\n",
      "Requirement already satisfied: accelerate in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel>=1.12.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/sdp/.local/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from datasets->optimum[neural-compressor]) (3.9.1)\n",
      "Requirement already satisfied: neural-compressor>=2.2.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.4.1)\n",
      "Requirement already satisfied: onnx in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.15.0)\n",
      "Requirement already satisfied: onnxruntime<1.15.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.14.1)\n",
      "Requirement already satisfied: networkx in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from torch>=1.11->optimum[neural-compressor]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from torch>=1.11->optimum[neural-compressor]) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (0.4.1)\n",
      "Requirement already satisfied: protobuf in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]) (4.25.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from coloredlogs->optimum[neural-compressor]) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from sympy->optimum[neural-compressor]) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from aiohttp->datasets->optimum[neural-compressor]) (4.0.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.2.14)\n",
      "Requirement already satisfied: opencv-python-headless in /home/sdp/.local/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (10.2.0)\n",
      "Requirement already satisfied: prettytable in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.9.0)\n",
      "Requirement already satisfied: psutil in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (5.9.7)\n",
      "Requirement already satisfied: py-cpuinfo in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (9.0.0)\n",
      "Requirement already satisfied: schema in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.7.5)\n",
      "Requirement already satisfied: scikit-learn in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.3.2)\n",
      "Requirement already satisfied: pycocotools in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (2.0.7)\n",
      "Requirement already satisfied: flatbuffers in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (23.5.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum[neural-compressor]) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/sdp/.local/lib/python3.10/site-packages (from pandas->datasets->optimum[neural-compressor]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from pandas->datasets->optimum[neural-compressor]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/sdp/.local/lib/python3.10/site-packages (from pandas->datasets->optimum[neural-compressor]) (2023.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from deprecated>=1.2.13->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum[neural-compressor]) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from prettytable->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.2.13)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.8.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from schema->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (21.6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.12.0; extra == \"neural-compressor\"->optimum[neural-compressor]) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install torch==2.1 --index-url https://download.pytorch.org/whl/cpu -qqq\n",
    "!python -m pip install intel-extension-for-pytorch -qqq\n",
    "!python -m pip install intel-openmp -qqq\n",
    "!python -m pip install optimum[neural-compressor] --upgrade-strategy eager -qqq\n",
    "\n",
    "# RESTART KERNEL !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acba1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize \"moshew/bge-small-en-v1.5_setfit-sst2-english\" using 100 samples:\n",
    "!cd ~ && git clone https://github.com/IntelLabs/fastRAG.git && cd -\n",
    "\n",
    "!python ~/fastRAG/scripts/optimizations/embedders/quantize_embedder.py \\\n",
    "    --quantize \\\n",
    "    --model_name \"moshew/bge-small-en-v1.5_setfit-sst2-english\" \\\n",
    "    --output_path bge-small-en-v1.5_setfit-sst2-quant/ \\\n",
    "    --sample_size 100 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enaQpBF9WRn9",
   "metadata": {
    "id": "enaQpBF9WRn9"
   },
   "outputs": [],
   "source": [
    "from setfit.exporters.utils import mean_pooling\n",
    "\n",
    "class INCSetFitModel:\n",
    "    def __init__(self, inc_model, tokenizer, model_head):\n",
    "        self.inc_model = inc_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_head = model_head\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        encoded_inputs = self.tokenizer(\n",
    "            inputs, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(self.inc_model.device)\n",
    "\n",
    "        outputs = self.inc_model(**encoded_inputs)\n",
    "        embeddings = mean_pooling(\n",
    "            outputs[\"last_hidden_state\"], encoded_inputs[\"attention_mask\"]\n",
    "        )\n",
    "        return self.model_head.predict(embeddings.cpu())\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qRviEk2WWRn9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRviEk2WWRn9",
    "outputId": "33f010a8-376e-4f0c-b21b-97fe25bf1a81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/utils/utility.py:46: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import parse_version\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/common/criterion.py:430: DeprecationWarning: Call to deprecated function (or staticmethod) criterion_registry. -- Deprecated since version 2.0.\n",
      "  @criterion_registry(\"KnowledgeDistillationLoss\", \"pytorch\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/common/criterion.py:963: DeprecationWarning: Call to deprecated function (or staticmethod) criterion_registry. -- Deprecated since version 2.0.\n",
      "  @criterion_registry(\"IntermediateLayersKnowledgeDistillationLoss\", \"pytorch\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/common/optimizer.py:116: DeprecationWarning: Call to deprecated function (or staticmethod) optimizer_registry. -- Deprecated since version 2.0.\n",
      "  @optimizer_registry(\"SGD\", \"tensorflow\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/common/optimizer.py:143: DeprecationWarning: Call to deprecated function (or staticmethod) optimizer_registry. -- Deprecated since version 2.0.\n",
      "  @optimizer_registry(\"AdamW\", \"tensorflow\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/common/optimizer.py:177: DeprecationWarning: Call to deprecated function (or staticmethod) optimizer_registry. -- Deprecated since version 2.0.\n",
      "  @optimizer_registry(\"SGD\", \"pytorch\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/strategy.py:73: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class TuneStrategy(object):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/bayesian.py:35: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class BayesianTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/auto_mixed_precision.py:33: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class AutoMixedPrecisionTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/mse_v2.py:32: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class MSE_V2TuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/mse.py:33: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class MSETuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/basic.py:32: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class BasicTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/exhaustive.py:26: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class ExhaustiveTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/strategy/random.py:29: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class RandomTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py:48: DeprecationWarning: Call to deprecated function (or staticmethod) pattern_registry. -- Deprecated since version 2.0.\n",
      "  @pattern_registry(pattern_type=\"tile_pattern_1x1\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py:58: DeprecationWarning: Call to deprecated function (or staticmethod) pattern_registry. -- Deprecated since version 2.0.\n",
      "  @pattern_registry(pattern_type=\"tile_pattern_2x2\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py:68: DeprecationWarning: Call to deprecated function (or staticmethod) pattern_registry. -- Deprecated since version 2.0.\n",
      "  @pattern_registry(pattern_type=\"tile_pattern_1x16\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py:78: DeprecationWarning: Call to deprecated function (or staticmethod) pattern_registry. -- Deprecated since version 2.0.\n",
      "  @pattern_registry(pattern_type=\"tile_pattern_4x1\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern.py:88: DeprecationWarning: Call to deprecated function (or staticmethod) pattern_registry. -- Deprecated since version 2.0.\n",
      "  @pattern_registry(pattern_type=\"tile_pattern_1x2\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruning_recipes/patterns/__init__.py:29: DeprecationWarning: Call to deprecated class PATTERNS. -- Deprecated since version 2.0.\n",
      "  patterns = PATTERNS()\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruner_legacy/pattern_lock.py:25: DeprecationWarning: Call to deprecated function (or staticmethod) pruner_registry. -- Deprecated since version 2.0.\n",
      "  class PatternLockPruner(Pruner):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruner_legacy/gradient_sensitivity.py:32: DeprecationWarning: Call to deprecated function (or staticmethod) pruner_registry. -- Deprecated since version 2.0.\n",
      "  class GradientSensitivityPruner(Pruner):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruner_legacy/magnitude.py:29: DeprecationWarning: Call to deprecated function (or staticmethod) pruner_registry. -- Deprecated since version 2.0.\n",
      "  class BasicMagnitudePruner(Pruner):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/pruner_legacy/group_lasso.py:30: DeprecationWarning: Call to deprecated function (or staticmethod) pruner_registry. -- Deprecated since version 2.0.\n",
      "  class GroupLassoPruner(BasicMagnitudePruner):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:496: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"F1\", \"tensorflow, tensorflow_itex, pytorch, mxnet, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:592: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"Accuracy\", \"tensorflow, tensorflow_itex, pytorch, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:709: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"Loss\", \"tensorflow, tensorflow_itex, pytorch, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:756: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"MAE\", \"tensorflow, tensorflow_itex, pytorch, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:815: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"RMSE\", \"tensorflow, tensorflow_itex, pytorch, mxnet, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:858: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"MSE\", \"tensorflow, tensorflow_itex, pytorch, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:918: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"topk\", \"tensorflow, tensorflow_itex\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:987: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"topk\", \"pytorch, mxnet, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1056: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"COCOmAPv2\", \"tensorflow, tensorflow_itex, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1218: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"mAP\", \"tensorflow, tensorflow_itex, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1375: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"COCOmAP\", \"tensorflow, tensorflow_itex, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1398: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"VOCmAP\", \"tensorflow, tensorflow_itex, onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1421: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"SquadF1\", \"tensorflow, tensorflow_itex\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1464: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"mIOU\", \"tensorflow, tensorflow_itex\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1517: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"GLUE\", \"onnxrt_qlinearops, onnxrt_integerops\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/metric.py:1582: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"ROC\", \"pytorch\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/bleu.py:66: DeprecationWarning: Call to deprecated class UnicodeRegex. -- Deprecated since version 2.0.\n",
      "  uregex = UnicodeRegex()\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/metric/bleu.py:90: DeprecationWarning: Call to deprecated function (or staticmethod) metric_registry. -- Deprecated since version 2.0.\n",
      "  @metric_registry(\"BLEU\", \"tensorflow, tensorflow_itex\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/nas/basic_nas.py:34: DeprecationWarning: Call to deprecated function (or staticmethod) nas_registry. -- Deprecated since version 2.0.\n",
      "  @nas_registry(\"Basic\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/nas/dynas.py:32: DeprecationWarning: Call to deprecated function (or staticmethod) nas_registry. -- Deprecated since version 2.0.\n",
      "  @nas_registry(\"DyNAS\")\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/contrib/strategy/sigopt.py:34: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class SigOptTuneStrategy(TuneStrategy):\n",
      "/storage/sdp/anaconda3/envs/setfit/lib/python3.10/site-packages/neural_compressor/experimental/contrib/strategy/tpe.py:44: DeprecationWarning: Call to deprecated function (or staticmethod) strategy_registry. -- Deprecated since version 2.0.\n",
      "  class TpeTuneStrategy(TuneStrategy):\n",
      "loading configuration file /home/sdp/dkorat/fastRAG/scripts/optimizations/embedders/quantized_model/inc_config.json\n",
      "INCConfig {\n",
      "  \"distillation\": {},\n",
      "  \"neural_compressor_version\": \"2.4.1\",\n",
      "  \"optimum_version\": \"1.16.2\",\n",
      "  \"pruning\": {},\n",
      "  \"quantization\": {\n",
      "    \"dataset_num_samples\": 100,\n",
      "    \"is_static\": true\n",
      "  },\n",
      "  \"save_onnx_model\": false,\n",
      "  \"torch_version\": \"2.1.0+cpu\",\n",
      "  \"transformers_version\": \"4.36.2\"\n",
      "}\n",
      "\n",
      "Quantized model was obtained with torch version 2.1.0+cpu but 2.1.0+cpu was found.\n",
      "intel_extension_for_pytorch version is 2.1.0+cpu\n",
      "2024-01-25 12:17:19,882 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: moshew/bge-small-en-v1.5_setfit-sst2-english\n",
      "2024-01-25 12:17:20,104 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from optimum.intel import INCModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bge_auto_opt_O4', model_max_length=512)\n",
    "inc_model_path = \"bge-small-en-v1.5_setfit-sst2-quant\"\n",
    "inc_model = INCModel.from_pretrained(inc_model_path)\n",
    "model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "inc_setfit_model = INCSetFitModel(inc_model, tokenizer, model.model_head)\n",
    "\n",
    "# Perform inference\n",
    "inc_setfit_model(test_dataset[\"text\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3DPl1ZpYqcBh",
   "metadata": {
    "id": "3DPl1ZpYqcBh"
   },
   "source": [
    "Time to benchmark this ONNX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O8jpZ3gdWRn9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8jpZ3gdWRn9",
    "outputId": "8d31c81a-67e4-4074-cf35-9f56d6dcdd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 0.004\n",
      "Accuracy on test set - 0.908\n",
      "Average latency (ms) - 2.61 +\\- 1.15\n",
      "Batch size: 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff0606307d14c2d847a53d1c77ed089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average throughput (bs=64) (samples/second): 1942.65 +\\- 555.73\\n\n",
      "Batch size: 512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4609f34a383d48cca8cb4242af1c0244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average throughput (bs=512) (samples/second): 2424.35 +\\- 472.96\\n\n",
      "Batch size: 8192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850bc118b83e4db482ca39cf1937767f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average throughput (bs=8192) (samples/second): 4978.16 +\\- 290.23\\n\n",
      "bge-small (PyTorch):\n",
      "size_mb: 127.324\n",
      "accuracy: 0.906\n",
      "time_avg_ms: 7.856\n",
      "time_std_ms: 0.820\n",
      "throughput_avg_64: 652.260\n",
      "throughput_std_64: 72.695\n",
      "throughput_avg_512: 1023.175\n",
      "throughput_std_512: 128.715\n",
      "throughput_avg_8192: 1449.017\n",
      "throughput_std_8192: 119.124\n",
      "\n",
      "bge-small (optimum-intel):\n",
      "size_mb: 0.004\n",
      "accuracy: 0.908\n",
      "time_avg_ms: 2.610\n",
      "time_std_ms: 1.153\n",
      "throughput_avg_64: 1942.650\n",
      "throughput_std_64: 555.732\n",
      "throughput_avg_512: 2424.352\n",
      "throughput_std_512: 472.964\n",
      "throughput_avg_8192: 4978.163\n",
      "throughput_std_8192: 290.228\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency speedup for 'bge-small (optimum-intel)': 3.01x\n"
     ]
    }
   ],
   "source": [
    "class INCPerformanceBenchmark(PerformanceBenchmark):\n",
    "    def __init__(self, *args, model_path, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def compute_size(self):\n",
    "        size_mb = Path(self.model_path).stat().st_size / (1024 * 1024)\n",
    "        print(f\"Model size (MB) - {size_mb:.3f}\")\n",
    "        return {\"size_mb\": size_mb}\n",
    "        \n",
    "pb = INCPerformanceBenchmark(\n",
    "    inc_setfit_model,\n",
    "    test_dataset,\n",
    "    \"bge-small (optimum-intel)\",\n",
    "    model_path=inc_model_path,\n",
    ")\n",
    "perf_metrics.update(pb.run_benchmark())\n",
    "\n",
    "for optim_type, results in perf_metrics.items():\n",
    "    s = [f\"{k}: {v:.3f}\" for k, v in results.items()]\n",
    "    print(f\"{optim_type}:\\n\" + \"\\n\".join(s) + \"\\n\")\n",
    "    \n",
    "plot_metrics(perf_metrics)\n",
    "\n",
    "def get_latency_speedup(model_name):\n",
    "    speedup = perf_metrics['bge-small (PyTorch)']['time_avg_ms'] / perf_metrics[model_name]['time_avg_ms']\n",
    "    return speedup\n",
    "print(f\"Latency speedup for 'bge-small (optimum-intel)': {get_latency_speedup('bge-small (optimum-intel)'):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cda299-1362-4232-8fb5-1abe069177ca",
   "metadata": {
    "id": "AiPUhOCNWRny"
   },
   "source": [
    "## 5. Optimizing for CPU using Intel Extension for Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e250d-0217-47d7-a48d-eaddc67081b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==2.1 --index-url https://download.pytorch.org/whl/cpu -qqq\n",
    "# !pip install intel-extension-for-pytorch==2.1.0 intel-openmp==2024.0.0 -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c113d3ba-7cb3-46d3-9be8-2e7e4811f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install gperftools -c conda-forge -y -qqq\n",
    "# !echo export LD_PRELOAD=${CONDA_PREFIX}/lib/libtcmalloc.so:${CONDA_PREFIX}/lib/libiomp5.so:$LD_PRELOAD >> ~/.bashrc\n",
    "# Restart kernel after this cell!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eae6b7-1c31-41c9-897c-8bf990db7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without conda, run these commands in the shell and restart this notebook\n",
    "\n",
    "# wget https://github.com/gperftools/gperftools/releases/download/gperftools-2.7.90/gperftools-2.7.90.tar.gz\n",
    "# tar -xzf gperftools-2.7.90.tar.gz \n",
    "# cd gperftools-2.7.90\n",
    "# ./configure --prefix=$HOME/.local\n",
    "# make\n",
    "# make install\n",
    "# echo export LD_PRELOAD=$HOME/.local/lib/libtcmalloc.so:$VIRTUAL_ENV/lib/libiomp5.so:$LD_PRELOAD >> ~/.bashrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2236ca-2f44-43fc-a083-83c43476f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import intel_extension_for_pytorch as ipex\n",
    "\n",
    "# pb = PerformanceBenchmark(model=setfit_model, dataset=test_dataset, optim_type=\"bge-small (IP import only)\")\n",
    "# perf_metrics = pb.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6773dc-0327-41e8-8dc3-0f401bf7ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from setfit import SetFitModel\n",
    "# setfit_model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "\n",
    "# pb = PerformanceBenchmark(model=setfit_model, dataset=test_dataset, optim_type=\"bge-small (Pytorch)\")\n",
    "# perf_metrics.update(pb.run_benchmark())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b00417-75c4-4e8f-ada4-3e5f44bcebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import intel_extension_for_pytorch as ipex\n",
    "# from setfit import SetFitModel\n",
    "\n",
    "# ipex_model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "# with torch.autocast('cpu', dtype=torch.bfloat16):\n",
    "#     ipex_model.model_body.eval()\n",
    "#     ipex_model.model_body = ipex.optimize(ipex_model.model_body, weights_prepack=False, dtype=torch.bfloat16)\n",
    "#     ipex_model.model_body = torch.compile(ipex_model.model_body, backend='ipex')\n",
    "\n",
    "# pb = PerformanceBenchmark(model=ipex_model, dataset=test_dataset, optim_type=\"bge-small (IPEX)\")\n",
    "# ipex_result_str = pb.run_benchmark()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f17376-3c70-47b0-adbb-0f60fc16934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Pytorch\\n-----\\n{pytorch_result_str}\")\n",
    "# print()\n",
    "# print(f\"IPEX\\n-----\\n{ipex_result_str}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
