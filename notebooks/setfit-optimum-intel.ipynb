{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76571396-8f54-40ed-9e81-6c7531e6eaee",
   "metadata": {
    "id": "76571396-8f54-40ed-9e81-6c7531e6eaee"
   },
   "source": [
    "# Efficiently Run SetFit Models with [`optimum-intel`](https://github.com/huggingface/optimum-intel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead5bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reproduce this notebook's results, launch it using `numactl` to gain better control on which resources you're running. \n",
    "# It is best to run on a single socket (`-m 0`):\n",
    "\n",
    "# NUM_THREADS=<NUM_AVAILABLE_CORES>\n",
    "# OMP_NUM_THREADS=$NUM_THREADS numactl -C 0-\"$(($NUM_THREADS-1))\" -m 0 jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc2a85",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Install by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839bd550",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install evaluate matplotlib -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a31653",
   "metadata": {},
   "source": [
    "If you're running this Notebook on Colab or some other cloud platform, you'll need to install the `setfit` library. Uncomment the following cell and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install setfit matplotlib -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72d255-ab98-4cc3-878b-6a60e08ccf6d",
   "metadata": {},
   "source": [
    "## Install `optimum-intel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9466ee2-5791-45b4-b69d-33bb5a82f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -U torch==2.1 --index-url https://download.pytorch.org/whl/cpu -qqq\n",
    "!python -m pip install --upgrade-strategy eager optimum[neural-compressor] -qqq\n",
    "!python -m pip install --upgrade-strategy eager intel-extension-for-pytorch -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493cd04-812f-461b-bb26-9225d76c2774",
   "metadata": {},
   "source": [
    "## 1. Benchmark SetFit using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a090c0-a065-4b3f-b803-5e518c73299f",
   "metadata": {},
   "source": [
    "Define the infrastructure for conducting latency, throughput and accuracy benchmarks, as well as a plotting function for the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55756fec-fc22-4590-84d7-2f3df37b9256",
   "metadata": {
    "id": "55756fec-fc22-4590-84d7-2f3df37b9256"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import os\n",
    "import warnings\n",
    "import subprocess\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def get_dir_size(path):\n",
    "    ps = subprocess.Popen(('du','-hk', path), stdout=subprocess.PIPE)\n",
    "    output = subprocess.check_output((\"awk\", \"{print $1/1024,$2}\"), stdin=ps.stdout)\n",
    "    ps.wait()\n",
    "    return float(output.split()[0].decode('utf-8'))\n",
    "\n",
    "class PerformanceBenchmark:\n",
    "    def __init__(self, model, dataset, optim_type, metric=\"accuracy\", model_path=None):\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.optim_type = optim_type\n",
    "        self.enable_autocast = 'optimum' in self.optim_type.lower()\n",
    "        self.metric = evaluate.load(metric)\n",
    "        self.model_path = model_path\n",
    "        \n",
    "    def compute_accuracy(self):\n",
    "        with torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "            preds = self.model.predict(self.dataset[\"text\"])\n",
    "        labels = self.dataset[\"label\"]\n",
    "        accuracy = self.metric.compute(predictions=preds, references=labels)\n",
    "        print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
    "        return accuracy\n",
    "\n",
    "    def compute_size(self):\n",
    "        if self.model_path is None:\n",
    "            state_dict = self.model.model_body.state_dict()\n",
    "            tmp_path = Path(\"model.pt\")\n",
    "            torch.save(state_dict, tmp_path)\n",
    "            size_mb = get_dir_size(tmp_path)\n",
    "            # Delete temporary file\n",
    "            tmp_path.unlink()\n",
    "        else:\n",
    "            size_mb = get_dir_size(self.model_path)\n",
    "        print(f\"Model size (MB) - {size_mb}\")\n",
    "        return {\"size_mb\": size_mb}\n",
    "\n",
    "    def compute_latency(self, query=\"that loves its characters and communicates something rather beautiful about human nature\"):\n",
    "        latencies = []\n",
    "        # Warmup\n",
    "        for _ in range(10):\n",
    "            with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                _ = self.model([query])\n",
    "        # Timed run\n",
    "        for _ in range(200):\n",
    "            start_time = perf_counter()\n",
    "            with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                _ = self.model([query])\n",
    "            latency = perf_counter() - start_time\n",
    "            latencies.append(latency)\n",
    "        # Compute run statistics\n",
    "        time_avg_ms = 1000 * np.mean(latencies)\n",
    "        time_std_ms = 1000 * np.std(latencies)\n",
    "        print(rf\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
    "        return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
    "\n",
    "    def compute_throughput(self, batch_sizes=[64, 512, 8192]):\n",
    "        results = {}\n",
    "        num_iters = 5\n",
    "        replications = int((max(batch_sizes) * (num_iters + 1)) / len(self.dataset))\n",
    "        replicated_ds = (self.dataset[\"text\"] * replications)[:max(batch_sizes) * num_iters]\n",
    "\n",
    "        for batch_size in batch_sizes:\n",
    "            throughputs = []\n",
    "            # Warmup\n",
    "            dataloader = iter(DataLoader(replicated_ds, batch_size=batch_size))\n",
    "            for _ in range(2):\n",
    "                with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                    self.model(next(dataloader))\n",
    "            # Timed run\n",
    "            dataloader = iter(DataLoader(replicated_ds, batch_size=batch_size))\n",
    "            num_loops = int(num_iters * (max(batch_sizes) / batch_size))\n",
    "            for _ in range(num_loops):\n",
    "                start_time = perf_counter()\n",
    "                with torch.no_grad(), torch.cpu.amp.autocast(enabled=self.enable_autocast):\n",
    "                    self.model(next(dataloader))\n",
    "                total_time =  perf_counter() - start_time\n",
    "                throughputs.append(batch_size / total_time)\n",
    "                \n",
    "            # Compute run statistics\n",
    "            avg_throughput = np.mean(throughputs)\n",
    "            std_throughput = np.std(throughputs)\n",
    "            print(rf\"Average throughput with {batch_size=} (samples/second): {avg_throughput:.2f} +\\- {std_throughput:.2f}\")\n",
    "            results[f\"throughput_avg_{batch_size}\"] = avg_throughput\n",
    "            results[f\"throughput_std_{batch_size}\"] = std_throughput\n",
    "        return results\n",
    "        \n",
    "    def run_benchmark(self):\n",
    "        all_metrics = {}\n",
    "        for run_metric in self.compute_size, self.compute_accuracy, self.compute_latency, self.compute_throughput:\n",
    "            all_metrics |= run_metric()\n",
    "        return {self.optim_type: all_metrics}\n",
    "        \n",
    "\n",
    "def plot_metrics(perf_metrics):\n",
    "    df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
    "\n",
    "    for idx in df.index:\n",
    "        df_opt = df.loc[idx]\n",
    "        plt.errorbar(\n",
    "            df_opt[\"time_avg_ms\"],\n",
    "            df_opt[\"accuracy\"] * 100,\n",
    "            xerr=df_opt[\"time_std_ms\"],\n",
    "            fmt=\"o\",\n",
    "            alpha=0.5,\n",
    "            ms=df_opt[\"size_mb\"] / 15,\n",
    "            label=idx,\n",
    "            capsize=5,\n",
    "            capthick=1,\n",
    "        )\n",
    "\n",
    "    legend = plt.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.ylim(63, 95)\n",
    "    # Use the slowest model to define the x-axis range\n",
    "    xlim = max([metrics[\"time_avg_ms\"] for metrics in perf_metrics.values()]) * 1.3\n",
    "    plt.xlim(0, xlim)\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"Average latency with batch_size=1 (ms)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d159ea96-f604-478c-b6a2-bf4cc5c57a5a",
   "metadata": {},
   "source": [
    "Load the dataset for running evaluations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867a9450-d8f0-4697-b3b4-a5ddf6b04906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "test_dataset = load_dataset(\"SetFit/sst2\")[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b47c9-7076-4510-8c1e-5c17445bae34",
   "metadata": {},
   "source": [
    "Run the benchmark with the standard PyTorch backend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "u-w99Y2qW4lU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-w99Y2qW4lU",
    "outputId": "57f0b8f7-6dad-4e90-c779-658a7de6e960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 128\n",
      "Accuracy on test set - 0.906\n",
      "Average latency (ms) - 27.57 +\\- 5.16\n",
      "Average throughput with batch_size=64 (samples/second): 699.33 +\\- 91.32\n",
      "Average throughput with batch_size=512 (samples/second): 846.31 +\\- 32.50\n",
      "Average throughput with batch_size=8192 (samples/second): 917.32 +\\- 49.33\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from setfit import SetFitModel\n",
    "\n",
    "small_model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "pb = PerformanceBenchmark(model=small_model, dataset=test_dataset, optim_type=\"bge-small (PyTorch)\")\n",
    "perf_metrics = pb.run_benchmark()\n",
    "\n",
    "# Save the benchmark results to file\n",
    "with open(\"baseline_metrics.json\", \"w\") as f:\n",
    "    json.dump(perf_metrics, f)\n",
    "plot_metrics(perf_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AiPUhOCNWRny",
   "metadata": {
    "id": "AiPUhOCNWRny"
   },
   "source": [
    "## 2. Optimizing with [`optimum-intel`](https://github.com/huggingface/optimum-intel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e60d191-db3b-49a3-a281-34ae9063cb25",
   "metadata": {},
   "source": [
    "ðŸ¤— Optimum Intel is the interface between the ðŸ¤— Transformers and Diffusers libraries and the different tools and libraries provided by Intel to accelerate end-to-end pipelines on Intel architectures.\n",
    "\n",
    "In order to optimize our SetFit model, we'll use Intel [Neural Compressor](https://www.intel.com/content/www/us/en/developer/tools/oneapi/neural-compressor.html) (`INC`), part of `optimum-intel`. \n",
    "We'll use INC to quantize the model body. This will compress the model in size and result in faster inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0557f9-8193-4059-8056-bfc50c00deef",
   "metadata": {},
   "source": [
    "First, let's load the Qasper calibration dataset which we'll use for the quantization process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8466be-f28d-4303-8511-15798806a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "def load_qasper_calibration_set(sample_size) -> Dataset:\n",
    "    train_set = load_dataset(\"allenai/qasper\")[\"train\"]\n",
    "    random.seed(666)\n",
    "    random_samples = random.sample(range(len(train_set)), sample_size)\n",
    "    random_queries = [random.sample(train_set[x][\"qas\"][\"question\"], 1)[0] for x in random_samples]\n",
    "    random_abstracts = [train_set[x][\"abstract\"] for x in random_samples]\n",
    "    samples = random.sample(random_queries + random_abstracts, sample_size)\n",
    "    random.shuffle(samples)\n",
    "    def gen():\n",
    "        for s in samples:\n",
    "            yield {\"text\": s}\n",
    "    return Dataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90c6ba-8f6e-4899-b404-ecebc0f7a78a",
   "metadata": {},
   "source": [
    "Define the desired quantization process using `optimum.intel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a7739dc-2a56-4960-8f56-7f3f74991fea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "import optimum.intel\n",
    "from neural_compressor.config import PostTrainingQuantConfig\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def quantize(model_name, output_path, calibration_set):\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=512, truncation=True)\n",
    "\n",
    "    vectorized_ds = calibration_set.map(preprocess_function, num_proc=10)\n",
    "    vectorized_ds = vectorized_ds.remove_columns([\"text\"])\n",
    "\n",
    "    quantizer = optimum.intel.INCQuantizer.from_pretrained(model)\n",
    "    quantization_config = PostTrainingQuantConfig(approach=\"static\", backend=\"ipex\", domain=\"nlp\")\n",
    "    quantizer.quantize(\n",
    "        quantization_config=quantization_config,\n",
    "        calibration_dataset=vectorized_ds,\n",
    "        save_directory=output_path,\n",
    "        batch_size=1,\n",
    "    )\n",
    "    tokenizer.save_pretrained(output_path)\n",
    "    \n",
    "model_name = \"moshew/bge-small-en-v1.5_setfit-sst2-english\"\n",
    "calibration_set = load_qasper_calibration_set(sample_size=100)\n",
    "optimum_model_path = os.path.expanduser(f\"~/models/{model_name}_opt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f935e3-d09a-4f44-87a0-f773b83e569a",
   "metadata": {},
   "source": [
    "Quantize our SetFit model using `optimum-intel` on 100 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508125d2-7bc4-4a6a-9b9d-1243ac0ff002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ONNX export is no supported for model with quantized embeddings\n",
      "2024-01-30 00:58:04 [INFO] Start auto tuning.\n",
      "2024-01-30 00:58:04 [INFO] Execute the tuning process due to detect the evaluation function.\n",
      "2024-01-30 00:58:04 [INFO] Adaptor has 5 recipes.\n",
      "2024-01-30 00:58:04 [INFO] 0 recipes specified by user.\n",
      "2024-01-30 00:58:04 [INFO] 3 recipes require future tuning.\n",
      "2024-01-30 00:58:05 [WARNING] Fail to remove /home/sdp/dkorat/setfit/notebooks/nc_workspace/2024-01-30_00-53-59/ipex_config_tmp.json.\n",
      "2024-01-30 00:58:05 [INFO] *** Initialize auto tuning\n",
      "2024-01-30 00:58:05 [INFO] {\n",
      "2024-01-30 00:58:05 [INFO]     'PostTrainingQuantConfig': {\n",
      "2024-01-30 00:58:05 [INFO]         'AccuracyCriterion': {\n",
      "2024-01-30 00:58:05 [INFO]             'criterion': 'relative',\n",
      "2024-01-30 00:58:05 [INFO]             'higher_is_better': True,\n",
      "2024-01-30 00:58:05 [INFO]             'tolerable_loss': 0.01,\n",
      "2024-01-30 00:58:05 [INFO]             'absolute': None,\n",
      "2024-01-30 00:58:05 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f72f0cd1af0>>,\n",
      "2024-01-30 00:58:05 [INFO]             'relative': 0.01\n",
      "2024-01-30 00:58:05 [INFO]         },\n",
      "2024-01-30 00:58:05 [INFO]         'approach': 'post_training_static_quant',\n",
      "2024-01-30 00:58:05 [INFO]         'backend': 'ipex',\n",
      "2024-01-30 00:58:05 [INFO]         'calibration_sampling_size': [\n",
      "2024-01-30 00:58:05 [INFO]             100\n",
      "2024-01-30 00:58:05 [INFO]         ],\n",
      "2024-01-30 00:58:05 [INFO]         'device': 'cpu',\n",
      "2024-01-30 00:58:05 [INFO]         'diagnosis': False,\n",
      "2024-01-30 00:58:05 [INFO]         'domain': 'nlp',\n",
      "2024-01-30 00:58:05 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2024-01-30 00:58:05 [INFO]         'excluded_precisions': [\n",
      "2024-01-30 00:58:05 [INFO]         ],\n",
      "2024-01-30 00:58:05 [INFO]         'framework': 'pytorch_ipex',\n",
      "2024-01-30 00:58:05 [INFO]         'inputs': [\n",
      "2024-01-30 00:58:05 [INFO]         ],\n",
      "2024-01-30 00:58:05 [INFO]         'model_name': '',\n",
      "2024-01-30 00:58:05 [INFO]         'ni_workload_name': 'quantization',\n",
      "2024-01-30 00:58:05 [INFO]         'op_name_dict': None,\n",
      "2024-01-30 00:58:05 [INFO]         'op_type_dict': None,\n",
      "2024-01-30 00:58:05 [INFO]         'outputs': [\n",
      "2024-01-30 00:58:05 [INFO]         ],\n",
      "2024-01-30 00:58:05 [INFO]         'quant_format': 'default',\n",
      "2024-01-30 00:58:05 [INFO]         'quant_level': 'auto',\n",
      "2024-01-30 00:58:05 [INFO]         'recipes': {\n",
      "2024-01-30 00:58:05 [INFO]             'smooth_quant': False,\n",
      "2024-01-30 00:58:05 [INFO]             'smooth_quant_args': {\n",
      "2024-01-30 00:58:05 [INFO]             },\n",
      "2024-01-30 00:58:05 [INFO]             'layer_wise_quant': False,\n",
      "2024-01-30 00:58:05 [INFO]             'layer_wise_quant_args': {\n",
      "2024-01-30 00:58:05 [INFO]             },\n",
      "2024-01-30 00:58:05 [INFO]             'fast_bias_correction': False,\n",
      "2024-01-30 00:58:05 [INFO]             'weight_correction': False,\n",
      "2024-01-30 00:58:05 [INFO]             'gemm_to_matmul': True,\n",
      "2024-01-30 00:58:05 [INFO]             'graph_optimization_level': None,\n",
      "2024-01-30 00:58:05 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2024-01-30 00:58:05 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2024-01-30 00:58:05 [INFO]             'pre_post_process_quantization': True,\n",
      "2024-01-30 00:58:05 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2024-01-30 00:58:05 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2024-01-30 00:58:05 [INFO]             ],\n",
      "2024-01-30 00:58:05 [INFO]             'dedicated_qdq_pair': False,\n",
      "2024-01-30 00:58:05 [INFO]             'rtn_args': {\n",
      "2024-01-30 00:58:05 [INFO]             },\n",
      "2024-01-30 00:58:05 [INFO]             'awq_args': {\n",
      "2024-01-30 00:58:05 [INFO]             },\n",
      "2024-01-30 00:58:05 [INFO]             'gptq_args': {\n",
      "2024-01-30 00:58:05 [INFO]             },\n",
      "2024-01-30 00:58:05 [INFO]             'teq_args': {\n",
      "2024-01-30 00:58:05 [INFO]             }\n",
      "2024-01-30 00:58:05 [INFO]         },\n",
      "2024-01-30 00:58:05 [INFO]         'reduce_range': None,\n",
      "2024-01-30 00:58:05 [INFO]         'TuningCriterion': {\n",
      "2024-01-30 00:58:05 [INFO]             'max_trials': 100,\n",
      "2024-01-30 00:58:05 [INFO]             'objective': [\n",
      "2024-01-30 00:58:05 [INFO]                 'performance'\n",
      "2024-01-30 00:58:05 [INFO]             ],\n",
      "2024-01-30 00:58:05 [INFO]             'strategy': 'basic',\n",
      "2024-01-30 00:58:05 [INFO]             'strategy_kwargs': None,\n",
      "2024-01-30 00:58:05 [INFO]             'timeout': 0\n",
      "2024-01-30 00:58:05 [INFO]         },\n",
      "2024-01-30 00:58:05 [INFO]         'use_bf16': True\n",
      "2024-01-30 00:58:05 [INFO]     }\n",
      "2024-01-30 00:58:05 [INFO] }\n",
      "2024-01-30 00:58:05 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-01-30 00:58:05 [INFO]  Found 12 blocks\n",
      "2024-01-30 00:58:05 [INFO] Attention Blocks: 12\n",
      "2024-01-30 00:58:05 [INFO] FFN Blocks: 12\n",
      "2024-01-30 00:58:06 [INFO] Attention Blocks : \n",
      "2024-01-30 00:58:06 [INFO] [['encoder.layer.0.attention.self.query', 'encoder.layer.0.attention.self.key', 'encoder.layer.0.attention.self.value', 'encoder.layer.0.attention.output.dense'], ['encoder.layer.1.attention.self.query', 'encoder.layer.1.attention.self.key', 'encoder.layer.1.attention.self.value', 'encoder.layer.1.attention.output.dense'], ['encoder.layer.2.attention.self.query', 'encoder.layer.2.attention.self.key', 'encoder.layer.2.attention.self.value', 'encoder.layer.2.attention.output.dense'], ['encoder.layer.3.attention.self.query', 'encoder.layer.3.attention.self.key', 'encoder.layer.3.attention.self.value', 'encoder.layer.3.attention.output.dense'], ['encoder.layer.4.attention.self.query', 'encoder.layer.4.attention.self.key', 'encoder.layer.4.attention.self.value', 'encoder.layer.4.attention.output.dense'], ['encoder.layer.5.attention.self.query', 'encoder.layer.5.attention.self.key', 'encoder.layer.5.attention.self.value', 'encoder.layer.5.attention.output.dense'], ['encoder.layer.6.attention.self.query', 'encoder.layer.6.attention.self.key', 'encoder.layer.6.attention.self.value', 'encoder.layer.6.attention.output.dense'], ['encoder.layer.7.attention.self.query', 'encoder.layer.7.attention.self.key', 'encoder.layer.7.attention.self.value', 'encoder.layer.7.attention.output.dense'], ['encoder.layer.8.attention.self.query', 'encoder.layer.8.attention.self.key', 'encoder.layer.8.attention.self.value', 'encoder.layer.8.attention.output.dense'], ['encoder.layer.9.attention.self.query', 'encoder.layer.9.attention.self.key', 'encoder.layer.9.attention.self.value', 'encoder.layer.9.attention.output.dense'], ['encoder.layer.10.attention.self.query', 'encoder.layer.10.attention.self.key', 'encoder.layer.10.attention.self.value', 'encoder.layer.10.attention.output.dense'], ['encoder.layer.11.attention.self.query', 'encoder.layer.11.attention.self.key', 'encoder.layer.11.attention.self.value', 'encoder.layer.11.attention.output.dense']]\n",
      "2024-01-30 00:58:06 [INFO] FFN Blocks : \n",
      "2024-01-30 00:58:06 [INFO] [['encoder.layer.0.intermediate.dense', 'encoder.layer.0.output.dense'], ['encoder.layer.1.intermediate.dense', 'encoder.layer.1.output.dense'], ['encoder.layer.2.intermediate.dense', 'encoder.layer.2.output.dense'], ['encoder.layer.3.intermediate.dense', 'encoder.layer.3.output.dense'], ['encoder.layer.4.intermediate.dense', 'encoder.layer.4.output.dense'], ['encoder.layer.5.intermediate.dense', 'encoder.layer.5.output.dense'], ['encoder.layer.6.intermediate.dense', 'encoder.layer.6.output.dense'], ['encoder.layer.7.intermediate.dense', 'encoder.layer.7.output.dense'], ['encoder.layer.8.intermediate.dense', 'encoder.layer.8.output.dense'], ['encoder.layer.9.intermediate.dense', 'encoder.layer.9.output.dense'], ['encoder.layer.10.intermediate.dense', 'encoder.layer.10.output.dense'], ['encoder.layer.11.intermediate.dense', 'encoder.layer.11.output.dense']]\n",
      "2024-01-30 00:58:06 [INFO] Pass query framework capability elapsed time: 821.55 ms\n",
      "2024-01-30 00:58:06 [INFO] Get FP32 model baseline.\n",
      "2024-01-30 00:58:06 [INFO] Save tuning history to /home/sdp/dkorat/setfit/notebooks/nc_workspace/2024-01-30_00-53-59/./history.snapshot.\n",
      "2024-01-30 00:58:06 [INFO] FP32 baseline is: [Accuracy: 1.0000, Duration (seconds): 0.0000]\n",
      "2024-01-30 00:58:06 [INFO] Quantize the model with default config.\n",
      "2024-01-30 00:58:26 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-01-30 00:58:26 [INFO] +---------------+-----------+----------+\n",
      "2024-01-30 00:58:26 [INFO] |    Op Type    |   Total   |   INT8   |\n",
      "2024-01-30 00:58:26 [INFO] +---------------+-----------+----------+\n",
      "2024-01-30 00:58:26 [INFO] |     matmul    |     24    |    24    |\n",
      "2024-01-30 00:58:26 [INFO] |     Linear    |     25    |    25    |\n",
      "2024-01-30 00:58:26 [INFO] +---------------+-----------+----------+\n",
      "2024-01-30 00:58:26 [INFO] Pass quantize model elapsed time: 20106.91 ms\n",
      "2024-01-30 00:58:26 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 1.0000|1.0000, Duration (seconds) (int8|fp32): 0.0000|0.0000], Best tune result is: [Accuracy: 1.0000, Duration (seconds): 0.0000]\n",
      "2024-01-30 00:58:26 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-01-30 00:58:26 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-01-30 00:58:26 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2024-01-30 00:58:26 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-01-30 00:58:26 [INFO] |      Accuracy      | 1.0000   |    1.0000     |     1.0000       |\n",
      "2024-01-30 00:58:26 [INFO] | Duration (seconds) | 0.0000   |    0.0000     |     0.0000       |\n",
      "2024-01-30 00:58:26 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-01-30 00:58:26 [INFO] [Strategy] Found a model that meets the accuracy requirements.\n",
      "2024-01-30 00:58:26 [INFO] Save tuning history to /home/sdp/dkorat/setfit/notebooks/nc_workspace/2024-01-30_00-53-59/./history.snapshot.\n",
      "2024-01-30 00:58:26 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2024-01-30 00:58:26 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2024-01-30 00:58:26 [INFO] Save deploy yaml to /home/sdp/dkorat/setfit/notebooks/nc_workspace/2024-01-30_00-53-59/deploy.yaml\n",
      "Model weights saved to /home/sdp/models/moshew/bge-small-en-v1.5_setfit-sst2-english_opt/pytorch_model.bin\n",
      "Configuration saved in /home/sdp/models/moshew/bge-small-en-v1.5_setfit-sst2-english_opt/inc_config.json\n"
     ]
    }
   ],
   "source": [
    "quantize(model_name, output_path=optimum_model_path, calibration_set=calibration_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8071a",
   "metadata": {},
   "source": [
    "Define a SetFit model wrapper which replaces the standard model body with the optimized model body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enaQpBF9WRn9",
   "metadata": {
    "id": "enaQpBF9WRn9"
   },
   "outputs": [],
   "source": [
    "from setfit.exporters.utils import mean_pooling\n",
    "\n",
    "class OptimumSetFitModel:\n",
    "    def __init__(self, inc_model, tokenizer, model_head):\n",
    "        self.optimum_model = inc_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model_head = model_head\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        encoded_inputs = self.tokenizer(\n",
    "            inputs, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        ).to(self.optimum_model.device)\n",
    "\n",
    "        outputs = self.optimum_model(**encoded_inputs)\n",
    "        embeddings = mean_pooling(\n",
    "            outputs[\"last_hidden_state\"], encoded_inputs[\"attention_mask\"]\n",
    "        )\n",
    "        return self.model_head.predict(embeddings.cpu())\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70f73e",
   "metadata": {},
   "source": [
    "Load the optimized model and the test dataset, and perform some inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qRviEk2WWRn9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qRviEk2WWRn9",
    "outputId": "33f010a8-376e-4f0c-b21b-97fe25bf1a81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/sdp/models/moshew/bge-small-en-v1.5_setfit-sst2-english_opt/inc_config.json\n",
      "INCConfig {\n",
      "  \"distillation\": {},\n",
      "  \"neural_compressor_version\": \"2.4.1\",\n",
      "  \"optimum_version\": \"1.16.2\",\n",
      "  \"pruning\": {},\n",
      "  \"quantization\": {\n",
      "    \"dataset_num_samples\": 100,\n",
      "    \"is_static\": true\n",
      "  },\n",
      "  \"save_onnx_model\": false,\n",
      "  \"torch_version\": \"2.1.2\",\n",
      "  \"transformers_version\": \"4.37.2\"\n",
      "}\n",
      "\n",
      "intel_extension_for_pytorch version is 2.1.100+cpu\n",
      "2024-01-30 01:11:04,227 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: moshew/bge-small-en-v1.5_setfit-sst2-english\n",
      "2024-01-30 01:11:05,583 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import optimum.intel\n",
    "from transformers import AutoTokenizer\n",
    "from setfit import SetFitModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(optimum_model_path, model_max_length=512)\n",
    "optimum_model = optimum.intel.INCModel.from_pretrained(optimum_model_path)\n",
    "model = SetFitModel.from_pretrained(\"moshew/bge-small-en-v1.5_setfit-sst2-english\")\n",
    "optimum_setfit_model = OptimumSetFitModel(optimum_model, tokenizer, model.model_head)\n",
    "\n",
    "# Reload test dataset\n",
    "test_dataset = load_dataset(\"SetFit/sst2\")[\"validation\"]\n",
    "\n",
    "# Perform inference\n",
    "optimum_setfit_model(test_dataset[\"text\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ce70d20-1e51-429c-bb11-c29835ea8130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size (MB) - 0.004\n",
      "Accuracy on test set - 0.908\n",
      "Average latency (ms) - 7.60 +\\- 0.08\n",
      "Average throughput with batch_size=64 (samples/second): 3246.93 +\\- 472.37\n",
      "Average throughput with batch_size=512 (samples/second): 2302.85 +\\- 457.24\n",
      "Average throughput with batch_size=8192 (samples/second): 882.14 +\\- 22.32\n",
      "bge-small (optimum-intel):\n",
      "size_mb: 0.004\n",
      "accuracy: 0.908\n",
      "time_avg_ms: 7.601\n",
      "time_std_ms: 0.083\n",
      "throughput_avg_64: 3246.933\n",
      "throughput_std_64: 472.370\n",
      "throughput_avg_512: 2302.853\n",
      "throughput_std_512: 457.242\n",
      "throughput_avg_8192: 882.138\n",
      "throughput_std_8192: 22.319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RUN OPTIMUM BENCHMARK ONLY\n",
    "pb = PerformanceBenchmark(\n",
    "    optimum_setfit_model,\n",
    "    test_dataset,\n",
    "    \"bge-small (optimum-intel)\",\n",
    "    model_path=optimum_model_path,\n",
    ")\n",
    "perf_metrics = {}\n",
    "perf_metrics.update(pb.run_benchmark())\n",
    "for optim_type, results in perf_metrics.items():\n",
    "    s = [f\"{k}: {v:.3f}\" for k, v in results.items()]\n",
    "    print(f\"{optim_type}:\\n\" + \"\\n\".join(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e7215f",
   "metadata": {},
   "source": [
    "Time to run the performance benchmark on our optimized SetFit model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O8jpZ3gdWRn9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O8jpZ3gdWRn9",
    "outputId": "8d31c81a-67e4-4074-cf35-9f56d6dcdd20"
   },
   "outputs": [],
   "source": [
    "pb = PerformanceBenchmark(\n",
    "    optimum_setfit_model,\n",
    "    test_dataset,\n",
    "    \"bge-small (optimum-intel)\",\n",
    "    model_path=optimum_model_path,\n",
    ")\n",
    "\n",
    "# Load baseline benchmark results\n",
    "with open(\"baseline_metrics.json\") as f:\n",
    "    perf_metrics = json.load(f)\n",
    "perf_metrics.update(pb.run_benchmark())\n",
    "\n",
    "# Print all results\n",
    "print()\n",
    "for optim_type, results in perf_metrics.items():\n",
    "    s = [f\"{k}: {v:.3f}\" for k, v in results.items()]\n",
    "    print(f\"{optim_type}:\\n\" + \"\\n\".join(s) + \"\\n\")\n",
    "    \n",
    "plot_metrics(perf_metrics)\n",
    "\n",
    "def get_latency_speedup(model_name):\n",
    "    speedup = perf_metrics['bge-small (PyTorch)']['time_avg_ms'] / perf_metrics[model_name]['time_avg_ms']\n",
    "    return speedup\n",
    "print(f\"Latency speedup for 'bge-small (optimum-intel)': {get_latency_speedup('bge-small (optimum-intel)'):.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48568c7b",
   "metadata": {},
   "source": [
    "The latency speedup for batch size 1 is 2.66x compared to the baseline, while the accuracy is unchanged!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
